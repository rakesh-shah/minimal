title: <p align="center"> Rakesh Shah </p>
logo: /assets/img/logo.png

description:
  <p align="center">
  <a href="pdf/resume.pdf">Resume</a> |
  <a href="https://www.linkedin.com/in/rakesh-shah-aa4a93102/">LinkedIn</a> |
  <a href="https://github.com/rakesh-shah">GitHub</a>
  
  <br>   
 With 5+ years of in depth experience in the field of Data Engineering ,DevOps - CICD - Jenkins , Building Cloud Infrastructure for AWS and GCP with excellent communication skills.

●  I have in depth knowledge of Big Data YARN and its processing, I have worked on various feature development for YARN 3.X.
● Along with the work on the internal processing of the Big Data tool I have also worked on the application level of it to solve various Data Ingestion and Integration issues.
● I have worked and have sound understanding of the various Big data tool stack like (Spark, Hadoop, Hive , Kafka) 
   and can work work seamlessly on Spark using various programming language like Python and Scala.
● Have experience with cloud-native software development methodologies (Agile, Waterfall) and tools for application development/ deployment including CI/CD (GitHub, GitLab).
● I have good experience in Retail and Manufacturing domain such as Retail Supply Chain and Manufacturing supply chain and cost optimization around this.
   Along with it taking requirement from business and framing it out in the entire Data Pipeline along with business data wrangling and manipulation in a optimized way.
● Apart from the Data Engineering skills I am packaged with DevOps, CICD and Infrastructure skills. 
   Have worked on various project to build the entire CICD pipeline solution and also done the Infrastructure deployment using Terraform as an automation tool.
● I am very well versed with cloud platform such as GCP and AWS and I can work on the project from very scratch to set up the project and then design the data pipeline.
● Along with it I have very good knowledge on programming language such as Java, Scala, Python and SQL - performing ETL.
● I am also good at data warehousing & dimensional modelling concepts.
● I can also work on Docker - Kubernetes to package and deploy the job and schedule the pipeline using Apache Airflow.
  <br>
  </p>



theme: jekyll-theme-minimal